# CI/CD Musings

__We’ll discuss briefly .Net core application building and continuous integration and Azure DevOps.__

The building of .Net apps has changed a lot since the introduction of .Net Core – nowadays all the functionality is baked into .Net CLI, which offers the functionality for restoring dependencies, building, running unit-tests and packaging the application. Azure DevOps has tasks which can be used in pipeline to implement these things, but the .Net core tasks basically is just a wrapper for the CLI command, so a lot of time one just ends up using the CLI directly with a command line task, often because it’s more efficient to chain commands than to run everything as a separate step. 

The common steps for the most basic .Net core application build are: restoring dependencies from Nuget package feeds (internal or external from nuget.org – often both), running dotnet build to compile binaries, running unit- or integration tests that have been implemented with .Net Core, Publishing the test and code coverage results, and publishing the compiled binaries as pipeline artifact for the CD pipeline to consume. The build often includes the generation of an SQL migration script, as .Net Core projects often use native Entity Framework for the relational database layer (not exactly sure how document database schema changes are handled, to be honest). 

Not sure if there is a direct equivlaent for linting in .Net core - you can nowadays setup code-style configuration for editor and build-time, so that is included in the build step. There used to be a lot of tooling in this space for .Net projects, like FxCop and Resharper, and I guess those still exists, or you can run SonarQube or something and get the code-style alongside static analysis.The pipeline probably should in any case include security-related tooling like static analysis, dependency analysis and something like generating a bill of materials documentation (ie. listing dependencies and their versions), but these are kind on top of the most common use case for various reasons – the most common being that devs don’t really like static code analysis.

There are plenty of CI/CD platforms around there, with Gitlab possibly being one of the most used among the mentioned ones and different kinds of Kubernetes-based scenarios. It’s honestly quite hard to see a scenario for using the on–premises installation of a CI/CD-platform – unless the company is required to keep everything in  a datacenter. Most of the cloud platforms do support running some sort of local deployment agent, which takes care of a lot of the on-prem scenarios, but I’m sure that there are some, say, embedded system scenarios that require on-prem platform. 

I used to maintain Azure DevOps Server (the artist previously known as Team Foundation Server) in on-prem, and honestly, the setup and server maintenance alone require so much extra effort that it’s not worth it. So for me the information I would need for making  a decision between on-prem and cloud CI/CD platform is 1) is there anything in the requirements that completely eliminates cloud platforms and 2) is there any way to change the requirements to fit in a cloud platform with self-hosted on-prem runners? If not, then it’s unfortunately an on-prem solution we need.
